# Идеи для управления контекстом Continue

## Проблема
Continue не поддерживает автоматическое подрезание истории чата. Когда контекст подходит к лимиту (32K токенов), нужно вручную управлять им.

## Решения

### 1. Скрипт для автоматического подрезания истории

**Идея:** Python скрипт, который:
- Находит файл истории Continue (обычно `~/.continue/history.json`)
- Подсчитывает токены в истории
- Подрезает старые сообщения, сохраняя:
  - Последние N сообщений (например, 5-10)
  - Важные сообщения (содержат код, команды, ключевые слова)
- Создаёт backup перед подрезанием

**Использование:**
```bash
python context_manager.py --max-tokens 25000 --keep-recent 5 --backup
```

**Автоматизация:** Настроить через cron/launchd для запуска каждый час.

### 2. Экспорт важных частей чата

**Идея:** Скрипт для экспорта истории в markdown:
- Фильтрует важные сообщения (содержат код, ошибки, решения)
- Экспортирует в структурированный markdown
- Сохраняет контекст перед очисткой истории

**Использование:**
```bash
python export_chat.py --output chat_backup.md
```

### 3. Мониторинг токенов

**Идея:** Утилита для отслеживания размера контекста:
- Подсчитывает токены в реальном времени (если Continue экспортирует метрики)
- Предупреждает когда приближается к лимиту
- Показывает какие файлы/сообщения занимают больше всего места

### 4. Альтернативные инструменты

#### Cursor
- Встроенное управление контекстом
- Автоматическое подрезание истории
- Более умная загрузка файлов
- https://cursor.sh

#### GitHub Copilot Chat
- Ограничение контекста через настройки
- Более эффективное использование токенов

#### Codeium Chat
- Бесплатный аналог
- Настройки лимита контекста
- https://codeium.com

### 5. Библиотеки для работы с токенами

#### tiktoken (Python)
Точный подсчёт токенов для разных моделей:
```python
import tiktoken
encoding = tiktoken.encoding_for_model("gpt-4")
tokens = encoding.encode("your text")
```

#### LangChain
Для сложных сценариев:
- `ConversationBufferWindowMemory` - автоматическое подрезание
- `ConversationSummaryMemory` - сжатие старых сообщений

### 6. Практические техники

1. **Периодическая очистка:** Новый чат каждые 10-15 сообщений
2. **Экспорт перед очисткой:** Сохранять важные части в markdown
3. **Использование @:** Точечная загрузка файлов вместо всего проекта
4. **Закрытие файлов:** Continue загружает открытые файлы автоматически
5. **Ограничение правил:** Временно отключать часть `.cursor/rules/*.mdc`

### 7. Настройки Continue (уже применены)

- `chunkSize: 500` - меньшие куски кода
- `maxFileSize: 500000` - файлы >500KB не индексируются
- `chunkOverlap: 100` - меньше перекрытия
- `.continueignore` - исключение больших файлов

### 8. Автоматизация через системные задачи

**macOS (launchd):**
- Создать plist файл для периодического подрезания
- Запускать каждый час автоматически

**Linux (cron):**
- Добавить в crontab для регулярного подрезания

**Windows (Task Scheduler):**
- Настроить задачу для автоматического запуска скрипта

## Рекомендации

1. **Использовать скрипт подрезания** - самый простой способ
2. **Настроить автоматизацию** - подрезание каждый час
3. **Делать backup** - перед подрезанием сохранять историю
4. **Мониторить токены** - использовать tiktoken для точного подсчёта
5. **Экспортировать важное** - сохранять контекст перед очисткой

## Приоритеты

1. ✅ Настроены параметры Continue (chunkSize, maxFileSize)
2. ✅ Создан .continueignore для больших файлов
3. ⏳ Создать скрипт подрезания истории (если нужно)
4. ⏳ Настроить автоматизацию (если нужно)
5. ⏳ Рассмотреть альтернативы (Cursor, Codeium)

